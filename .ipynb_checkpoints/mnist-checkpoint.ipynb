{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = input_data.read_data_sets('mnist/', one_hot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 784)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treinamento = mnist.train.images\n",
    "y_treinamento = mnist.train.labels\n",
    "x_teste = mnist.test.images\n",
    "y_teste = mnist.test.labels\n",
    "x_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3803922 , 0.37647063, 0.3019608 ,\n",
       "       0.46274513, 0.2392157 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.3529412 , 0.5411765 , 0.9215687 ,\n",
       "       0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 , 0.9215687 ,\n",
       "       0.9843138 , 0.9843138 , 0.9725491 , 0.9960785 , 0.9607844 ,\n",
       "       0.9215687 , 0.74509805, 0.08235294, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.54901963,\n",
       "       0.9843138 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.7411765 , 0.09019608, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8862746 , 0.9960785 , 0.81568635,\n",
       "       0.7803922 , 0.7803922 , 0.7803922 , 0.7803922 , 0.54509807,\n",
       "       0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 , 0.2392157 ,\n",
       "       0.5019608 , 0.8705883 , 0.9960785 , 0.9960785 , 0.7411765 ,\n",
       "       0.08235294, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.32156864, 0.0509804 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.13333334,\n",
       "       0.8352942 , 0.9960785 , 0.9960785 , 0.45098042, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.32941177, 0.9960785 ,\n",
       "       0.9960785 , 0.9176471 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.32941177, 0.9960785 , 0.9960785 , 0.9176471 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4156863 , 0.6156863 ,\n",
       "       0.9960785 , 0.9960785 , 0.95294124, 0.20000002, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.09803922, 0.45882356, 0.8941177 , 0.8941177 ,\n",
       "       0.8941177 , 0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.94117653, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.26666668, 0.4666667 , 0.86274517,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 ,\n",
       "       0.9960785 , 0.9960785 , 0.9960785 , 0.9960785 , 0.5568628 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.14509805, 0.73333335,\n",
       "       0.9921569 , 0.9960785 , 0.9960785 , 0.9960785 , 0.8745099 ,\n",
       "       0.8078432 , 0.8078432 , 0.29411766, 0.26666668, 0.8431373 ,\n",
       "       0.9960785 , 0.9960785 , 0.45882356, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4431373 , 0.8588236 , 0.9960785 , 0.9490197 , 0.89019614,\n",
       "       0.45098042, 0.34901962, 0.12156864, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7843138 , 0.9960785 , 0.9450981 ,\n",
       "       0.16078432, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.6627451 , 0.9960785 ,\n",
       "       0.6901961 , 0.24313727, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.18823531,\n",
       "       0.9058824 , 0.9960785 , 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.07058824, 0.48627454, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.9960785 , 0.9960785 ,\n",
       "       0.6509804 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.54509807, 0.9960785 , 0.9333334 , 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.8235295 , 0.9803922 , 0.9960785 ,\n",
       "       0.65882355, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9490197 , 0.9960785 , 0.93725497, 0.22352943, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,\n",
       "       0.3372549 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01960784,\n",
       "       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_treinamento[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 10)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_treinamento[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_teste.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Classe: 3')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.imshow(x_treinamento[102].reshape((28, 28)), cmap = 'gray')\n",
    "plt.title('Classe: ' + str(np.argmax(y_treinamento[102])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 784)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch, y_batch = mnist.train.next_batch(64)\n",
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Forecasters Attributes\n",
    "neuronios_entrada = x_treinamento.shape[1]\n",
    "neuronios_entrada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "397"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neurons\n",
    "neuronios_oculta1 = int((x_treinamento.shape[1] + y_treinamento.shape[1]) / 2)\n",
    "neuronios_oculta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Neurons\n",
    "neuronios_oculta2 = neuronios_oculta1\n",
    "neuronios_oculta3 = neuronios_oculta1\n",
    "neuronios_saida = y_treinamento.shape[1]\n",
    "neuronios_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\fabio\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "#Weights\n",
    "w = {'oculta1': tf.Variable(tf.random_normal([neuronios_entrada, neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta1, neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta2, neuronios_oculta3])),\n",
    "     'saida':   tf.Variable(tf.random_normal([neuronios_oculta3, neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bias\n",
    "b = {'oculta1': tf.Variable(tf.random_normal([neuronios_oculta1])),\n",
    "     'oculta2': tf.Variable(tf.random_normal([neuronios_oculta2])),\n",
    "     'oculta3': tf.Variable(tf.random_normal([neuronios_oculta3])),\n",
    "     'saida': tf.Variable(tf.random_normal([neuronios_saida]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Placeholders\n",
    "xph = tf.placeholder('float', [None, neuronios_entrada])\n",
    "yph = tf.placeholder('float', [None, neuronios_saida])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, w, b):\n",
    "    camada_oculta1 = tf.nn.relu(tf.add(tf.matmul(x, w['oculta1']), b['oculta1']))\n",
    "    camada_oculta2 = tf.nn.relu(tf.add(tf.matmul(camada_oculta1, w['oculta2']), b['oculta2']))\n",
    "    camada_oculta3 = tf.nn.relu(tf.add(tf.matmul(camada_oculta2, w['oculta3']), b['oculta3']))\n",
    "    camada_saida = tf.add(tf.matmul(camada_oculta3, w['saida']), b['saida'])\n",
    "    return camada_saida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "modelo = mlp(xph, w, b)\n",
    "erro = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = modelo, labels = yph))\n",
    "otimizador = tf.train.AdamOptimizer(learning_rate = 0.0001).minimize(erro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "previsoes = tf.nn.softmax(modelo)\n",
    "previsoes_corretas = tf.equal(tf.argmax(previsoes, 1), tf.argmax(yph, 1))\n",
    "taxa_acerto = tf.reduce_mean(tf.cast(previsoes_corretas, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Error:29088.64 Accuracy: [0.1015625]\n",
      "Epoch: 101 Error:11436.285 Accuracy: [0.2421875]\n",
      "Epoch: 201 Error:6083.291 Accuracy: [0.453125]\n",
      "Epoch: 301 Error:4506.525 Accuracy: [0.5234375]\n",
      "Epoch: 401 Error:3994.7305 Accuracy: [0.53125]\n",
      "Epoch: 501 Error:3691.8442 Accuracy: [0.6328125]\n",
      "Epoch: 601 Error:2534.6318 Accuracy: [0.6953125]\n",
      "Epoch: 701 Error:3045.8696 Accuracy: [0.6796875]\n",
      "Epoch: 801 Error:1864.3873 Accuracy: [0.734375]\n",
      "Epoch: 901 Error:1574.5846 Accuracy: [0.78125]\n",
      "Epoch: 1001 Error:2010.5985 Accuracy: [0.765625]\n",
      "Epoch: 1101 Error:2123.6753 Accuracy: [0.7890625]\n",
      "Epoch: 1201 Error:1545.0107 Accuracy: [0.7890625]\n",
      "Epoch: 1301 Error:2051.5962 Accuracy: [0.7578125]\n",
      "Epoch: 1401 Error:1152.8289 Accuracy: [0.84375]\n",
      "Epoch: 1501 Error:1504.2078 Accuracy: [0.8203125]\n",
      "Epoch: 1601 Error:1363.9788 Accuracy: [0.8359375]\n",
      "Epoch: 1701 Error:1467.0771 Accuracy: [0.828125]\n",
      "Epoch: 1801 Error:1120.8427 Accuracy: [0.8359375]\n",
      "Epoch: 1901 Error:1272.2765 Accuracy: [0.8359375]\n",
      "Epoch: 2001 Error:825.0231 Accuracy: [0.859375]\n",
      "Epoch: 2101 Error:1062.8645 Accuracy: [0.859375]\n",
      "Epoch: 2201 Error:1589.769 Accuracy: [0.8046875]\n",
      "Epoch: 2301 Error:1394.3391 Accuracy: [0.828125]\n",
      "Epoch: 2401 Error:369.49475 Accuracy: [0.9140625]\n",
      "Epoch: 2501 Error:2044.1257 Accuracy: [0.8359375]\n",
      "Epoch: 2601 Error:526.5851 Accuracy: [0.8828125]\n",
      "Epoch: 2701 Error:730.4859 Accuracy: [0.90625]\n",
      "Epoch: 2801 Error:1022.7391 Accuracy: [0.84375]\n",
      "Epoch: 2901 Error:967.43616 Accuracy: [0.8671875]\n",
      "Epoch: 3001 Error:495.39343 Accuracy: [0.90625]\n",
      "Epoch: 3101 Error:557.5443 Accuracy: [0.8828125]\n",
      "Epoch: 3201 Error:619.0596 Accuracy: [0.9140625]\n",
      "Epoch: 3301 Error:1178.4233 Accuracy: [0.828125]\n",
      "Epoch: 3401 Error:1013.54346 Accuracy: [0.8828125]\n",
      "Epoch: 3501 Error:588.68933 Accuracy: [0.8515625]\n",
      "Epoch: 3601 Error:1198.2433 Accuracy: [0.859375]\n",
      "Epoch: 3701 Error:880.5283 Accuracy: [0.8671875]\n",
      "Epoch: 3801 Error:393.30508 Accuracy: [0.90625]\n",
      "Epoch: 3901 Error:557.6652 Accuracy: [0.8984375]\n",
      "Epoch: 4001 Error:329.06165 Accuracy: [0.921875]\n",
      "Epoch: 4101 Error:807.5757 Accuracy: [0.875]\n",
      "Epoch: 4201 Error:959.04956 Accuracy: [0.90625]\n",
      "Epoch: 4301 Error:832.1985 Accuracy: [0.90625]\n",
      "Epoch: 4401 Error:359.44202 Accuracy: [0.890625]\n",
      "Epoch: 4501 Error:626.07745 Accuracy: [0.921875]\n",
      "Epoch: 4601 Error:881.57886 Accuracy: [0.875]\n",
      "Epoch: 4701 Error:413.65656 Accuracy: [0.8984375]\n",
      "Epoch: 4801 Error:917.2414 Accuracy: [0.8984375]\n",
      "Epoch: 4901 Error:655.2565 Accuracy: [0.890625]\n",
      "Epoch: 5001 Error:563.4011 Accuracy: [0.8671875]\n",
      "Epoch: 5101 Error:601.38 Accuracy: [0.8984375]\n",
      "Epoch: 5201 Error:428.01398 Accuracy: [0.9375]\n",
      "Epoch: 5301 Error:606.63855 Accuracy: [0.921875]\n",
      "Epoch: 5401 Error:531.7394 Accuracy: [0.90625]\n",
      "Epoch: 5501 Error:405.33618 Accuracy: [0.921875]\n",
      "Epoch: 5601 Error:556.6696 Accuracy: [0.8984375]\n",
      "Epoch: 5701 Error:280.69727 Accuracy: [0.921875]\n",
      "Epoch: 5801 Error:289.0447 Accuracy: [0.921875]\n",
      "Epoch: 5901 Error:501.92334 Accuracy: [0.921875]\n",
      "Epoch: 6001 Error:614.6349 Accuracy: [0.890625]\n",
      "Epoch: 6101 Error:229.91504 Accuracy: [0.9375]\n",
      "Epoch: 6201 Error:202.1481 Accuracy: [0.953125]\n",
      "Epoch: 6301 Error:500.95395 Accuracy: [0.8984375]\n",
      "Epoch: 6401 Error:330.35266 Accuracy: [0.953125]\n",
      "Epoch: 6501 Error:357.4996 Accuracy: [0.921875]\n",
      "Epoch: 6601 Error:639.78 Accuracy: [0.875]\n",
      "Epoch: 6701 Error:480.93994 Accuracy: [0.9296875]\n",
      "Epoch: 6801 Error:365.2735 Accuracy: [0.9140625]\n",
      "Epoch: 6901 Error:372.9706 Accuracy: [0.9375]\n",
      "Epoch: 7001 Error:405.0193 Accuracy: [0.9375]\n",
      "Epoch: 7101 Error:103.12511 Accuracy: [0.96875]\n",
      "Epoch: 7201 Error:294.60083 Accuracy: [0.921875]\n",
      "Epoch: 7301 Error:277.4313 Accuracy: [0.953125]\n",
      "Epoch: 7401 Error:266.13446 Accuracy: [0.9453125]\n",
      "Epoch: 7501 Error:383.26892 Accuracy: [0.9375]\n",
      "Epoch: 7601 Error:314.5887 Accuracy: [0.9140625]\n",
      "Epoch: 7701 Error:313.14642 Accuracy: [0.9375]\n",
      "Epoch: 7801 Error:166.78836 Accuracy: [0.9765625]\n",
      "Epoch: 7901 Error:143.97775 Accuracy: [0.9453125]\n",
      "Epoch: 8001 Error:219.96921 Accuracy: [0.96875]\n",
      "Epoch: 8101 Error:332.34515 Accuracy: [0.9375]\n",
      "Epoch: 8201 Error:317.41138 Accuracy: [0.9453125]\n",
      "Epoch: 8301 Error:366.77954 Accuracy: [0.90625]\n",
      "Epoch: 8401 Error:171.4201 Accuracy: [0.953125]\n",
      "Epoch: 8501 Error:198.38351 Accuracy: [0.9296875]\n",
      "Epoch: 8601 Error:413.47556 Accuracy: [0.921875]\n",
      "Epoch: 8701 Error:512.7748 Accuracy: [0.9375]\n",
      "Epoch: 8801 Error:64.28455 Accuracy: [0.984375]\n",
      "Epoch: 8901 Error:283.4706 Accuracy: [0.9609375]\n",
      "Epoch: 9001 Error:489.06622 Accuracy: [0.9296875]\n",
      "Epoch: 9101 Error:139.24667 Accuracy: [0.9453125]\n",
      "Epoch: 9201 Error:45.778015 Accuracy: [0.96875]\n",
      "Epoch: 9301 Error:159.91211 Accuracy: [0.9609375]\n",
      "Epoch: 9401 Error:33.1994 Accuracy: [0.9921875]\n",
      "Epoch: 9501 Error:194.10614 Accuracy: [0.953125]\n",
      "Epoch: 9601 Error:184.50179 Accuracy: [0.9765625]\n",
      "Epoch: 9701 Error:271.3275 Accuracy: [0.96875]\n",
      "Epoch: 9801 Error:502.4536 Accuracy: [0.9609375]\n",
      "Epoch: 9901 Error:131.92612 Accuracy: [0.9765625]\n",
      "Training Complete!\n",
      "0.9147\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoca in range(10000):\n",
    "        x_batch, y_batch = mnist.train.next_batch(128)\n",
    "        _, custo = sess.run([otimizador, erro], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "        if epoca % 100 == 0:\n",
    "            acc = sess.run([taxa_acerto], feed_dict = {xph: x_batch, yph: y_batch})\n",
    "            print('Epoch: ' + str((epoca + 1)) + ' Error:' + str(custo) + ' Accuracy: ' + str(acc))\n",
    "            \n",
    "    print('Training Complete!')\n",
    "    print(sess.run(taxa_acerto, feed_dict = {xph: x_teste, yph: y_teste}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
